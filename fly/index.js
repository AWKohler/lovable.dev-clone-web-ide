import http from "http";
import fs from "fs";
import path from "path";
import os from "os";
import unzipper from "unzipper";
import { spawn } from "child_process";

const port = process.env.PORT || 8080;

const AUTH_HEADER = "authorization";
const EXPECTED_TOKEN = process.env.WORKER_AUTH_TOKEN;

if (!EXPECTED_TOKEN) {
  throw new Error("WORKER_AUTH_TOKEN is not set");
}

function run(cmd, args, { cwd, env, logBuffer }) {
  return new Promise((resolve, reject) => {
    const child = spawn(cmd, args, { cwd, env });

    child.stdout.on("data", (d) => {
      const text = d.toString();
      logBuffer.push(text);
    });
    child.stderr.on("data", (d) => {
      const text = d.toString();
      logBuffer.push(text);
    });

    child.on("close", (code) => {
      if (code === 0) resolve();
      else reject(new Error(`${cmd} exited with code ${code}`));
    });
  });
}

// Recursively read all files in a directory
function readDirRecursive(dir, baseDir = dir) {
  const files = [];
  const entries = fs.readdirSync(dir, { withFileTypes: true });

  for (const entry of entries) {
    const fullPath = path.join(dir, entry.name);
    if (entry.isDirectory()) {
      files.push(...readDirRecursive(fullPath, baseDir));
    } else {
      const relativePath = path.relative(baseDir, fullPath);
      const content = fs.readFileSync(fullPath, "utf8");
      files.push({ path: relativePath, content });
    }
  }

  return files;
}

const server = http.createServer(async (req, res) => {
  if (req.method !== "POST") {
    res.writeHead(405);
    return res.end();
  }

  const auth = req.headers[AUTH_HEADER];
  if (auth !== `Bearer ${EXPECTED_TOKEN}`) {
    res.writeHead(401);
    return res.end("unauthorized");
  }

  const deployKey = req.headers["x-convex-deploy-key"];
  if (!deployKey) {
    res.writeHead(400);
    return res.end("Missing X-Convex-Deploy-Key");
  }

  const jobDir = fs.mkdtempSync(path.join(os.tmpdir(), "convex-job-"));
  const logBuffer = [];

  try {
    // Save ZIP
    const zipPath = path.join(jobDir, "snapshot.zip");
    const writeStream = fs.createWriteStream(zipPath);
    req.pipe(writeStream);

    await new Promise((resolve, reject) => {
      writeStream.on("finish", resolve);
      writeStream.on("error", reject);
    });

    // Extract ZIP
    await fs
      .createReadStream(zipPath)
      .pipe(unzipper.Extract({ path: jobDir }))
      .promise();

    logBuffer.push("Installing dependencies...\n");

    await run("npm", ["install", "--omit=dev"], {
      cwd: jobDir,
      env: process.env,
      logBuffer,
    });

    logBuffer.push("\nRunning convex deploy...\n");

    await run("convex", ["deploy"], {
      cwd: jobDir,
      env: {
        ...process.env,
        CONVEX_DEPLOY_KEY: deployKey,
      },
      logBuffer,
    });

    logBuffer.push("\n✅ Convex deploy completed successfully\n");

    // Read generated files from convex/_generated/
    let generatedFiles = [];
    const generatedDir = path.join(jobDir, "convex", "_generated");
    if (fs.existsSync(generatedDir)) {
      logBuffer.push("\nCollecting generated types...\n");
      generatedFiles = readDirRecursive(generatedDir, generatedDir);
      logBuffer.push(`Collected ${generatedFiles.length} generated file(s)\n`);
    }

    // Return JSON response with logs and generated files
    res.writeHead(200, { "Content-Type": "application/json; charset=utf-8" });
    res.end(
      JSON.stringify({
        success: true,
        logs: logBuffer.join(""),
        generatedFiles: generatedFiles.map((f) => ({
          path: f.path,
          content: f.content,
        })),
      })
    );
  } catch (err) {
    console.error(err);
    logBuffer.push(`\n❌ Error: ${err.message}\n`);
    res.writeHead(500, { "Content-Type": "application/json; charset=utf-8" });
    res.end(
      JSON.stringify({
        success: false,
        logs: logBuffer.join(""),
        error: err.message,
        generatedFiles: [],
      })
    );
  }
});

server.listen(port, () => {
  console.log(`Worker listening on ${port}`);
});
